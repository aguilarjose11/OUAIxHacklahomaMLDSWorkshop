{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abcfdae2",
   "metadata": {},
   "source": [
    "UC Irvine's Adult Data Set Notebook\n",
    "============================\n",
    "\n",
    "This Jupyter notebook contains the code used during OUAIxHacklahoma workshop for Fall 2021 (December 1st, 2021). Credits given to University of California, Irvine for collecting and organizing the provided [\"Adult Data Set\"](https://archive.ics.uci.edu/ml/datasets/Adult) dataset.\n",
    "\n",
    "Objectives\n",
    "--------------\n",
    "\n",
    "This jupyter notebook implements a solution to best categorize whether an adult will make _more than_ or _less than_ \\$50,000 a year. The dataset uses different attributes to help best predict the goal. The label attribute in this dataset is __income__. Unkown data values will be defined by a `?` symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed03cec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c06857",
   "metadata": {},
   "source": [
    "Data Obtention\n",
    "============\n",
    "\n",
    "The UCI's Adult dataset is provided in the datasets folder. We use Pandas's `read_csv` function. More formats are supported; read more in pandas [documentation](https://pandas.pydata.org/docs/reference/io.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983bee17",
   "metadata": {},
   "outputs": [],
   "source": [
    "adult = pd.read_csv('datasets/adult.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d5831d",
   "metadata": {},
   "source": [
    "Data Discovery\n",
    "============\n",
    "\n",
    "__It is important for us to gain an understanding of our data before performing any kind of learning or analysis.__ It is important to note that by \"Discovery\" we mean understanding what attributes and data types the dataset includes. This also includes identifying usefull and useless data attributes (such as dates or indexes). At this stage we want to focus in geting a grasp on what needs to be done next to achieve our goals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0faa5484",
   "metadata": {},
   "source": [
    "### Look at the dataset's attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd19b588",
   "metadata": {},
   "outputs": [],
   "source": [
    "adult.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a075764b",
   "metadata": {},
   "source": [
    "### Look at the 7 first and last entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ebea21",
   "metadata": {},
   "outputs": [],
   "source": [
    "adult.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c16a6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adult.tail(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0873c511",
   "metadata": {},
   "source": [
    "### See what kind of data the dataset contains.\n",
    "Note that workclass, education, marital.status, occupation, relationship, race, sex, native.country, and income are type `object`. Since we are using a CSV we can rest assured that we are dealing with a text datatype, most probably a _categorical_ data type. \n",
    "\n",
    "Do be careful when using other datatypes such as JSON or pickle, for whole python objects could be in the dataset; thus, requiring further data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef1f5fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adult.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0a63c6",
   "metadata": {},
   "source": [
    "We can further probe into categorical data by using the `value_counts()` function. This provides us a matrix with values and the number of times they are found in the data. Play around with the other suspected categorical data attributes to further learn more about them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0763fd24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adult['education'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad71af1b",
   "metadata": {},
   "source": [
    "## Dataset Statistics\n",
    "\n",
    "The `describe()` function provided by Pandas allows us to get a glimpse into the statistical relationships going on in the dataset. This information can be useful to gain a better understanding of the dataset itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4085126d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adult.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ea3d58",
   "metadata": {},
   "source": [
    "Note that only __6__ attributes are displayed. This is due to the fact that `describe()` only looks at numerical data to produce its statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb08041",
   "metadata": {},
   "source": [
    "#### Plotting the dataset\n",
    "\n",
    "We can further gain knowledge by ploting the dataset. Pay close attention to the distribution! The `hist()` function allows us to plot a historgram. These are very useful when dealing with data that may have different statistical distributions. The `bins` parameter allows us to choose how many \"rectangles\" to include in a single histogram. The `figsize` allows us to determine the size of the histogram (y, x)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a4a977",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adult.hist(bins=50, figsize=(20, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04dd195f",
   "metadata": {},
   "source": [
    "# Dataset Preparation\n",
    "\n",
    "Once we have gained a better understanding of the kind of data that we are dealing with, it is important to avoid making assumptions on the dataset. This is because certain attributes may not influence the final prediction as we may think. This is crucial when seeking the best machine learning model.\n",
    "\n",
    "When working with machine learning, it is very important for us to prepare the dataset for training. This is accomplished by first separating the data into two parts: _Training_ and _Testing_. Doing this will allow us to maintain a neutral position on the dataset and avoid outside bias from interfering with the learning process. Additionally, we will be using the testing dataset after we perform learning in order for us to test how well our model does with unseen data. At the end of the day, we care about a model that can do well with unseen data rather than just the data that it has learned already.\n",
    "\n",
    "`StratifiedShuffleSplit` is a commonly-used splitting technique to separate the training from the testing sub-datasets. It uses a categorical attribute to keep the best representation among the datasets. In data science, the __80/20__ splitting rule is the most used splitting distribution. We keep 80% for our training data and 20% for our testing data.\n",
    "\n",
    "### How do we choose which attribute to split on?\n",
    "\n",
    "Expert advise is best when deciding what attribute to use. In general, it is a good idea to split your dataset using as basis an attribute that may be very important for machine learning; thus, it is benefitial to maintain the best representation of the data possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48fc0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "attrib = 'education'\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_i, test_i in split.split(adult, adult[attrib]):\n",
    "    strat_train_set = adult.loc[train_i]\n",
    "    strat_test_set = adult.loc[test_i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f68e114",
   "metadata": {},
   "source": [
    "Splitted data insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a374d129",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "strat_train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dea20e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_test_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea35990d",
   "metadata": {},
   "source": [
    "We can appreciate how the distribution in the number of samples is kept across the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1734a435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train dataset\n",
    "strat_train_set[attrib].value_counts().plot(figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207981dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dataset\n",
    "strat_test_set[attrib].value_counts().plot(figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c756057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The distribution is kept if the graphs of the other datasets resemble this one.\n",
    "adult[attrib].value_counts().plot(figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b30904e",
   "metadata": {},
   "source": [
    "From now on, __only use the training dataset__ to perform any further data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328969f5",
   "metadata": {},
   "source": [
    "## Correlations\n",
    "\n",
    "Given that in data science we are attempting to find correlations within the data that could give the machine learning model better insights, it is a good idea to check what attributes may be the most useful for this. Note that this will only work with numerical data, thus, we may not be able to use simple Pearson correlation on attributes that are categorical or `object` type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba36753",
   "metadata": {},
   "source": [
    "The most used correlation measure is Pearson correlation. As explained, this only works with numerical data. Note that our label attribute (income) is of type `object`. As explained, this means that we are dealing most likely with a categorical label. We can create a temporal numerical representation of the categorial label by using `OrdinalEncoder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d01e091",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "oe = OrdinalEncoder()\n",
    "strat_train_set['income_ord'] = oe.fit_transform(strat_train_set[['income']])\n",
    "\n",
    "strat_train_set['income_ord']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75c58ad",
   "metadata": {},
   "source": [
    "Note how education.num has a correlation of 0.33. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e46a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a correlation matrix\n",
    "corr_matrix = strat_train_set.corr()\n",
    "corr_matrix['income_ord'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c392c152",
   "metadata": {},
   "source": [
    "Using the OrdinalEncoder, it is possible for us to see the correlation of other attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4304960",
   "metadata": {},
   "source": [
    "### Scatter Matrix\n",
    "\n",
    "We can further visualize any correlations among the data attributes by using a correlation matrix. This can help us better observe the above correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e1ee13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "attributes = ['age', 'capital.gain', 'hours.per.week', 'capital.loss', 'education.num', 'fnlwgt', 'income_ord']\n",
    "scatter_matrix(strat_train_set[attributes], figsize=(12, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347aa194",
   "metadata": {},
   "source": [
    "# Attribute Engineering\n",
    "\n",
    "Often, it is a good idea to try and combine attributes to further enrich the data of information that may not be there by the individual attributes. This is particularily used for numerical attributes. __Avoid using the label when combining features.__ This is important since the learning model may get information by the label indirectly through the combined attribute. Further, the label will not be available when we actually deploy the model (since we are trying to predict the label to begin with!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c490b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy dataset so that we can play more safely with our dataset.\n",
    "attr_eng_train_set = strat_train_set.copy()\n",
    "attr_eng_train_set['cap.gain.per.week.hour'] = attr_eng_train_set['capital.gain']/attr_eng_train_set['hours.per.week']\n",
    "attr_eng_train_set['cap.loss.per.week.hour'] = attr_eng_train_set['capital.loss']/attr_eng_train_set['hours.per.week']\n",
    "attr_eng_train_set['cap.gain.per.education.num'] = attr_eng_train_set['capital.gain']/attr_eng_train_set['education.num']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96339e9",
   "metadata": {},
   "source": [
    "Note that `cap.gain.per.week.hour` and `cap.loss.per.week.hour` do not introduce more correlation. On the other hand, `education.num.per.cap.gain` introduces a slightly better correlation that is higher than the other two attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5190eb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = attr_eng_train_set.corr()\n",
    "corr_matrix['income_ord'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ecb074",
   "metadata": {},
   "outputs": [],
   "source": [
    "attr_eng_train_set.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004a3255",
   "metadata": {},
   "source": [
    "Since we are dealing with the stratified data, we will need to add the new attribute we engineered back to the dataset as a whole. In this case, we will add `cap.gain.per.education.num` given that it adds more correlation. Additionally, we will re-shufflesplit the data to account for the fact that `education.num` seems to be the best predictor explored so far.\n",
    "\n",
    "Further inspection of `education.num` reveals that the attribute, although numerical, is also a categorical attribute. Because of this, we can use it for the StratifiedShuffleSplit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5e8023",
   "metadata": {},
   "outputs": [],
   "source": [
    "adult['education.num'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f74e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adult['cap.gain.per.education.num'] = adult['capital.gain']/adult['education.num']\n",
    "attrib = 'education.num'\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_i, test_i in split.split(adult, adult[attrib]):\n",
    "    strat_train_set = adult.loc[train_i]\n",
    "    strat_test_set = adult.loc[test_i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5aa17f",
   "metadata": {},
   "source": [
    "# Dataset Preparation\n",
    "\n",
    "Some attributes may have values that may not be useful for learning. In particular, one shall be wary of undefined/invalid values. Oftentimes these values manifest themselves as `NaN` values. In our case, these values are displayed as `?`. This is explained in the dataset's description. This is why it is important to read a dataset description before using. Some authors use different standards when crafting datasets. The three offending attributes in our case are: `workclass, occupation, native.country`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d70beda",
   "metadata": {},
   "outputs": [],
   "source": [
    "adult['workclass'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfc981a",
   "metadata": {},
   "outputs": [],
   "source": [
    "adult['occupation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71c8b43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adult['native.country'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cb8baa",
   "metadata": {},
   "source": [
    "There are different ways one can deal with missing data:\n",
    "\n",
    "1. Remove offending samples.\n",
    "  - Good when dealing with a small number of samples.\n",
    "2. Remove attribute.\n",
    "  - Good when we have too many values missing and we have plenty attributes.\n",
    "3. Set value.\n",
    "  - Good when there is high correlations among other attributes or there is enough samples that we can use mean, median, or its ok to set them to 0.\n",
    "  \n",
    "In our case, there are several things to consider:\n",
    "\n",
    "1. `workclass` and `occupation` share the same samples that have missing data. If we remove those particular samples,  we would clean both attributes without having to loose too many samples.\n",
    "2. `native.country` is a categorical type. Additionally, there is a small number of offending samples. Either labeling them USA or removing them can be good actions. In this case, we will remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17582dbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Note that many samples have both workclass and occupation missing!\n",
    "adult[adult['workclass'] == '?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095c7027",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "adult[adult['native.country'] == '?']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5597d1",
   "metadata": {},
   "source": [
    "#### Clean `workclass`, `occupation`, `native.country`\n",
    "\n",
    "We keep only the samples that do not have `?` as values. We only loose __2399__ data samples (~7%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8eac84",
   "metadata": {},
   "outputs": [],
   "source": [
    "adult = adult[adult['workclass'] != '?']\n",
    "adult = adult[adult['occupation'] != '?']\n",
    "adult = adult[adult['native.country'] != '?']\n",
    "adult.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17d16de",
   "metadata": {},
   "outputs": [],
   "source": [
    "adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc09afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "attrib = 'education.num'\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_i, test_i in split.split(adult, adult[attrib]):\n",
    "    strat_train_set = adult.loc[train_i]\n",
    "    strat_test_set = adult.loc[test_i]\n",
    "strat_train_set.reset_index(inplace=True, drop=True)\n",
    "strat_test_set.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e719f0b",
   "metadata": {},
   "source": [
    "## Dealing with Categorical Data\n",
    "\n",
    "Often, machine learning models need special representation of categorical attributes. The reason for this is on their training algorithms that use optimization strategies that require numerical values. Often, it is enough for us to replace categorical values with integers. The categorical values we will be dealing with are: `workclass`, `education`, `education.num`, `marital.status`, `occupation`, `relationship`, `race`, `sex`, `native.country`. Additionally, the label also needs to be encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecc0a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f64519",
   "metadata": {},
   "source": [
    "### Encoding Categorical Attributes\n",
    "\n",
    "There are seberal common ways to deal with categorical attributes. The first one is to encode categories using numbers for each respective category. In this manner, pre-school education could be given a value of 0, elementary education a value of 1, middle-school education a value of 2, and high-school education a value of 3. This can be achieved by using eithwe `OrdinalEncoder` or `LabelEncoder` from scikit-learn.\n",
    "\n",
    "Often, a third option is used called `OneHotEncoder`. One-hot encoding uses several columns to encode categorical data in bit-string format. for example, encoding the education attribute would use 4 columns (following on the aforementioned example in the previous paragraph). Each colum would represent whether a sample is of one type or another. For example, if the first column has a 1 and all other columns have a 0, then, we could say that the education level is of pre-school. If the third column has a 1 and all other columns a value of 0, then we could say that the education level for that sample is middle-school. \n",
    "\n",
    "The benefit of using one-hot encoding is that by not placing a numerical value on the categories, we do not create a relationship among them where there may not exist one. For example, giving a higher value to single compare to married in marital status could cause the machine learning algorithm to pick an inexisting relationship among attributes. One-hot encoding alleviates this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec9da52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "cat_attrs = ['workclass', 'education', 'education.num', 'marital.status', 'occupation', \n",
    "             'relationship', 'race', 'sex', 'native.country']\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(adult[cat_attrs])\n",
    "ohe_train = pd.DataFrame(ohe.transform(strat_train_set[cat_attrs]).toarray())\n",
    "ohe_test = pd.DataFrame(ohe.transform(strat_test_set[cat_attrs]).toarray())\n",
    "\n",
    "# Drop categorical data\n",
    "strat_train_set.drop(cat_attrs, axis=1, inplace=True)\n",
    "strat_test_set.drop(cat_attrs, axis=1, inplace=True)\n",
    "\n",
    "# Replace with one-hot encoded data\n",
    "strat_train_set = strat_train_set.join(ohe_train)\n",
    "strat_test_set = strat_test_set.join(ohe_test)\n",
    "\n",
    "# Encode income as an ordinal value.\n",
    "oe = OrdinalEncoder()\n",
    "strat_train_set['income'] = oe.fit_transform(strat_train_set[['income']])\n",
    "strat_test_set['income'] = oe.fit_transform(strat_test_set[['income']])\n",
    "\n",
    "# Kepp column names as string\n",
    "strat_train_set.columns = strat_train_set.columns.astype(str)\n",
    "strat_test_set.columns = strat_test_set.columns.astype(str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b75d3d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "strat_train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e3ec50",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_test_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e309878",
   "metadata": {},
   "source": [
    "## Feature Scalling\n",
    "\n",
    "Sometimes, data comes in varying degrees of scales. For example, our dataset attributes `fnlwgt`, `capital.gain`, and `cap.gain.per.education.num` are widely distributed. This is evident when we look at the `describe()` function of the dataset and note the difference between max and min statistics. These large numbers can make machine learning models take longer than expected to learn a solution. to make learning easier, it is good practice to \"standarize\" or \"noramlize\" our data. There are two main ways by which this can be achieved:\n",
    "\n",
    "- min-max scaling:\n",
    "  - We use the difference between the minimum and maximum values in the dataset to keep data between 0 and 1.\n",
    "- standarization:\n",
    "  - We use the mean to \"de-mean\" the data. Then, we divide the data by the standard deviation to scale values to unit variances.\n",
    "\n",
    "Note that the main difference is that min-max gives values between 0 and 1 and standarization does not.\n",
    "\n",
    "There is no particular rule to when to use each type of scaling. It is a good idea to try both and compare how much each improves data prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8133d37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "adult.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37e29d9",
   "metadata": {},
   "source": [
    "When performing the scaling, one may be tempted to scale the whole dataset. This __shall be avoided__. The reason is that because we split the dataset into a training and testing datasets, and these sub-datasets should be independent of each other, applying feature scalling on the dataset as a whole before splitting will introduce a certain degree of dependence. This is bad because we are interested in obtaining a model that will perform well regardless of whether the data has been seen previously or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cda07c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "to_scale = ['fnlwgt', 'capital.gain', 'cap.gain.per.education.num']\n",
    "# We use two scalers to isolate both datasets\n",
    "ss_train = StandardScaler()\n",
    "ss_test = StandardScaler()\n",
    "# mm_train = MinMaxScaler()\n",
    "# mm_test = MinMaxScaler()\n",
    "\n",
    "strat_train_set[to_scale] = ss_train.fit_transform(strat_train_set[to_scale])\n",
    "strat_test_set[to_scale] = ss_test.fit_transform(strat_test_set[to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23ccd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_set.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f723d385",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "\n",
    "There is a plethora of different machine learning models. Depending on the application, some models may be better than others. In this case, we are dealing with a classification problem. Because of this, some recomended models to try are:\n",
    "\n",
    "- Support Vector Machine\n",
    "- Logistic Regression\n",
    "- Naive Bayes\n",
    "- K-Nearest Neighbors\n",
    "- Decision Trees\n",
    "- Random Forests\n",
    "- Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a5cf23",
   "metadata": {},
   "source": [
    "For training, we remove the labels from the training data. Leaving them in the dataset will be reminiscent to giving test answers to a class. It is common practice to use an X variable for the de-labeled data and y for the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06d04dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Remove labels.\n",
    "X = strat_train_set.drop(['income'], axis=1)\n",
    "# Put labels in different variable\n",
    "y = strat_train_set['income']\n",
    "\n",
    "# Here it is where the magic happens!\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3c671d",
   "metadata": {},
   "source": [
    "In order for us to distinguish among models, it is a good idea to pick an accuracy estimator. There are many accuracy estimators that are used in different circumstances. Some of the most used are root mean squared error (RMSE), mean absolute error (MAE), and sklearn's classification accuracy score. Since we are dealing with a classification task, the accuracy score is our best bet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018c5b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_pred = model.predict(X)\n",
    "test_X = strat_test_set.drop(['income'], axis=1)\n",
    "test_pred = model.predict(test_X)\n",
    "\n",
    "test_y = strat_test_set['income']\n",
    "\n",
    "train_rmse = np.sqrt(mean_squared_error(y, train_pred))\n",
    "test_rmse = np.sqrt(mean_squared_error(test_y, test_pred))\n",
    "\n",
    "train_mae = mean_absolute_error(y, train_pred)\n",
    "test_mae = mean_absolute_error(test_y, test_pred)\n",
    "\n",
    "train_as = accuracy_score(y, train_pred)\n",
    "test_as = accuracy_score(test_y, test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f64e6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training Score: {train_rmse} | Testing Score: {test_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e25012",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training Score: {train_mae} | Testing Score: {test_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cc93de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training Score: {train_as} | Testing Score: {test_as}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4f92d4",
   "metadata": {},
   "source": [
    "# Model Fine Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e626af2",
   "metadata": {},
   "source": [
    "As it can be appreciated, the scores obtained above are not phenomenal. The model definetely learns something, but the score reglects that when the model is put to the test, it still struggles. There can be many reasons for this, but one of the main reasons is that the model has not been fine tuned. Machine learning models come with pre-set attributes that may or may not be the best for a particular dataset. Because of this, it is a good idea to test different parameters. Often, testing new parameters will help the model perform better. Check out scikit-learn's documentation to find out about what parameters you can test to try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96856025",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        'n_estimators': [50, 75, 100, 125, 150],\n",
    "        'criterion': ['gini', ]\n",
    "    },\n",
    "]\n",
    "model = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(model, param_grid, cv=10, scoring='accuracy', return_train_score=True)\n",
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e683c52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "train_pred = best_model.predict(strat_train_set.drop(['income'], axis=1))\n",
    "test_pred = best_model.predict(strat_test_set.drop(['income'], axis=1))\n",
    "\n",
    "train_rmse = np.sqrt(mean_squared_error(strat_train_set['income'], train_pred))\n",
    "test_rmse = np.sqrt(mean_squared_error(strat_test_set['income'], test_pred))\n",
    "\n",
    "train_mae = mean_absolute_error(strat_train_set['income'], train_pred)\n",
    "test_mae = mean_absolute_error(strat_test_set['income'], test_pred)\n",
    "\n",
    "train_as = accuracy_score(strat_train_set['income'], train_pred)\n",
    "test_as = accuracy_score(strat_test_set['income'], test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a16524",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training Score: {train_rmse} | Testing Score: {test_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70544933",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training Score: {train_mae} | Testing Score: {test_mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef4ffa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training Score: {train_as} | Testing Score: {test_as}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
