{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed7c4755",
   "metadata": {},
   "source": [
    "# Medical Cost Dataset\n",
    "This Jupyter notebook contains the code used during OUAIxHacklahoma workshop for Fall 2021 (December 1st, 2021). Credits given to _miri choi_ from Kaggle for collecting and organizing the provided [\"Medical Cost Dataset\"](https://www.kaggle.com/mirichoi0218/insurance).\n",
    "\n",
    "Objectives\n",
    "--------------\n",
    "\n",
    "This jupyter notebook implements a solution to best categorize charges incurred to a person for insurance. This task is exclusively of regression, and the insurance cost is in dollars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8b6d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a8c9f9",
   "metadata": {},
   "source": [
    "Data Obtention\n",
    "============\n",
    "\n",
    "The Medical Cost dataset is provided in the datasets folder. We use Pandas's `read_csv` function. More formats are supported; read more in pandas [documentation](https://pandas.pydata.org/docs/reference/io.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b648cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance = pd.read_csv('datasets/insurance.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4364ea66",
   "metadata": {},
   "source": [
    "Data Discovery\n",
    "============\n",
    "\n",
    "__It is important for us to gain an understanding of our data before performing any kind of learning or analysis.__ It is important to note that by \"Discovery\" we mean understanding what attributes and data types the dataset includes. This also includes identifying usefull and useless data attributes (such as dates or indexes). At this stage we want to focus in geting a grasp on what needs to be done next to achieve our goals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e470cf92",
   "metadata": {},
   "source": [
    "### Look at the dataset's attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6b845f",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d114275",
   "metadata": {},
   "source": [
    "### Look at the 7 first and last entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcb4fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0647f9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance.tail(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2069abc",
   "metadata": {},
   "source": [
    "### See what kind of data the dataset contains.\n",
    "Note that `sex`, `smoker`, and `region` attributes are shown as `object` Dtype. When data is first imported into sklearn, strings are represented as object types. Oftentimes, this data is categorical, and because we have imported a CSV data file we can rest assured that the columns will be categorical. We can further prove this by taking a look at the values that exist within the suspected categorical attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9396c346",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5c263c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "insurance['region'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe718d8",
   "metadata": {},
   "source": [
    "## Dataset Statistics\n",
    "\n",
    "The `describe()` function provided by Pandas allows us to get a glimpse into the statistical relationships going on in the dataset. This information can be useful to gain a better understanding of the dataset itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c73028f",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6b97e4",
   "metadata": {},
   "source": [
    "Note that only __4__ attributes are displayed. This is due to the fact that the describe function only looks at numerical data. Other types of data are ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3188877",
   "metadata": {},
   "source": [
    "#### Plotting the dataset\n",
    "\n",
    "We can further gain knowledge by ploting the dataset. Pay close attention to the distribution! The `hist()` function allows us to plot a historgram. These are very useful when dealing with data that may have different statistical distributions. The `bins` parameter allows us to choose how many \"rectangles\" to include in a single histogram. The `figsize` allows us to determine the size of the histogram (y, x)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12667bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance.hist(bins=50, figsize=(20, 15))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7989255d",
   "metadata": {},
   "source": [
    "# Dataset Preparation\n",
    "\n",
    "Once we have gained a better understanding of the kind of data that we are dealing with, it is important to avoid making assumptions on the dataset. This is because certain attributes may not influence the final prediction as we may think. This is crucial when seeking the best machine learning model.\n",
    "\n",
    "When working with machine learning, it is very important for us to prepare the dataset for training. This is accomplished by first separating the data into two parts: _Training_ and _Testing_. Doing this will allow us to maintain a neutral position on the dataset and avoid outside bias from interfering with the learning process. Additionally, we will be using the testing dataset after we perform learning in order for us to test how well our model does with unseen data. At the end of the day, we care about a model that can do well with unseen data rather than just the data that it has learned already.\n",
    "\n",
    "`StratifiedShuffleSplit` is a commonly-used splitting technique to separate the training from the testing sub-datasets. It uses a categorical attribute to keep the best representation among the datasets. In data science, the __80/20__ splitting rule is the most used splitting distribution. We keep 80% for our training data and 20% for our testing data.\n",
    "\n",
    "### How do we choose which attribute to split on?\n",
    "\n",
    "Expert advise is best when deciding what attribute to use. In general, it is a good idea to split your dataset using as basis an attribute that may be very important for machine learning; thus, it is benefitial to maintain the best representation of the data possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21bd5e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "attrib = 'age'\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_i, test_i in split.split(insurance, insurance[attrib]):\n",
    "    strat_train_set = insurance.loc[train_i]\n",
    "    strat_test_set = insurance.loc[test_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3555d3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1bcc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_test_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a748caab",
   "metadata": {},
   "source": [
    "We can apreciate the dataset distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19a46db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train dataset\n",
    "strat_train_set[attrib].value_counts().hist(bins=100, figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d86b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dataset\n",
    "strat_test_set[attrib].value_counts().hist(bins=100, figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9c2d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The distribution is kept if the graphs of the other datasets resemble this one.\n",
    "insurance[attrib].value_counts().hist(bins=100, figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9fc7be",
   "metadata": {},
   "source": [
    "From now on, __only use the training dataset__ to perform any further data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b795cb",
   "metadata": {},
   "source": [
    "## Correlations\n",
    "\n",
    "Given that in data science we are attempting to find correlations within the data that could give the machine learning model better insights, it is a good idea to check what attributes may be the most useful for this. Note that this will only work with numerical data, thus, we may not be able to use simple Pearson correlation on attributes that are categorical or `object` type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeeb24ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a correlation matrix\n",
    "corr_matrix = strat_train_set.corr()\n",
    "corr_matrix['charges'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c071b01b",
   "metadata": {},
   "source": [
    "It seems to be that age is the best predictor of insurance cost. Note that this correlation value is very low. Since a significant number of attributes are `object` type it is worth the attempt to try and convert those attributes to a numerical encoding to check if there are better correlations. To do this, we can use sklearn's OrdinalEncoder to convert categorical strings into numerical form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32d0acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "cat_cols = ['sex', 'smoker', 'region']\n",
    "oe = OrdinalEncoder()\n",
    "strat_train_set[cat_cols] = oe.fit_transform(strat_train_set[cat_cols])\n",
    "\n",
    "strat_train_set.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc55aad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a correlation matrix and check correlations again\n",
    "corr_matrix = strat_train_set.corr()\n",
    "corr_matrix['charges'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f749fc",
   "metadata": {},
   "source": [
    "Note how being a smoker gives a positive correlation. This correlation is also much better than any other attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6261c049",
   "metadata": {},
   "source": [
    "### Scatter Matrix\n",
    "\n",
    "We can further visualize any correlations among the data attributes by using a correlation matrix. This can help us better observe the above correlations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba27553",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72181eeb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "attributes = ['age', 'sex', 'bmi', 'children', 'smoker', 'region', 'charges']\n",
    "scatter_matrix(strat_train_set[attributes], figsize=(12, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b29924",
   "metadata": {},
   "source": [
    "# Attribute Engineering\n",
    "\n",
    "Often, it is a good idea to try and combine attributes to further enrich the data of information that may not be there by the individual attributes. This is particularily used for numerical attributes. __Avoid using the label when combining features.__ This is important since the learning model may get information by the label indirectly through the combined attribute. Further, the label will not be available when we actually deploy the model (since we are trying to predict the label to begin with!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9059515",
   "metadata": {},
   "source": [
    "The most promising attributes are `bmi` and `age`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2adb32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy dataset so that we can play more safely with our dataset.\n",
    "attr_eng_train_set = strat_train_set.copy()\n",
    "attr_eng_train_set['bmi.per.year'] = attr_eng_train_set['bmi']/attr_eng_train_set['age']\n",
    "attr_eng_train_set['bmi.year'] = attr_eng_train_set['bmi']*attr_eng_train_set['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1595eec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = attr_eng_train_set.corr()\n",
    "corr_matrix['charges'].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefff5c5",
   "metadata": {},
   "source": [
    "Note that `bmi.per.year` only has a slight negative correlation with charges. `bmi.year` on the other hand adds a better correlation than most other attributes. Because of this, we will add this new attribute combination to the original dataset so that when we resplit the dataset for learning, we keep this new attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e99872",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance['bmi.year'] = insurance['bmi']*insurance['age']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e92b75",
   "metadata": {},
   "source": [
    "With our newly conceived knowledge about the dataset, we can resplit the dataset, now using a better estimate for splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76b2bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "attrib = 'region'\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_i, test_i in split.split(insurance, insurance[attrib]):\n",
    "    strat_train_set = insurance.loc[train_i]\n",
    "    strat_test_set = insurance.loc[test_i]\n",
    "\n",
    "strat_train_set.reset_index(inplace=True, drop=True)\n",
    "strat_test_set.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dce540e",
   "metadata": {},
   "source": [
    "# Dataset Preparation\n",
    "\n",
    "Commonly, datasets have missing or invalid data. These data samples usually show as NaN values when looking at the data. In our case we do not have such an issue. This dataset has been precleaned by the dataset provided; thus, no further need for dataset cleaning is needed. In our other example with the Adult dataset we will encounter several missing values. Further discussion on how to work with incomplete data is given in the jupyter notebook for that dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33db475",
   "metadata": {},
   "source": [
    "## Dealing with Categorical Data\n",
    "\n",
    "Often, machine learning models need special representation of categorical attributes. The reason for this is on their training algorithms that use optimization strategies that require numerical values. Often, it is enough for us to replace categorical values with integers. The categorical values we will be dealing with are:`sex`, `smoker`, `region`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c630b568",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5c6837",
   "metadata": {},
   "source": [
    "### Encoding Categorical Attributes\n",
    "\n",
    "There are seberal common ways to deal with categorical attributes. The first one is to encode categories using numbers for each respective category. In this manner, region northwest could be given a value of 0, northeast a value of 1, southwest a value of 2, and southeast a value of 3. This can be achieved by using eithwe `OrdinalEncoder` or `LabelEncoder` from scikit-learn.\n",
    "\n",
    "Often, a third option is used called `OneHotEncoder`. One-hot encoding uses several columns to encode categorical data in bit-string format. for example, encoding the region attribute would use 4 columns. Each colum would represent whether a sample is of one type or another. For example, if the first column has a 1 and all other columns have a 0, then, we could say that the region is northwest. If the third column has a 1 and all other columns a value of 0, then we could say that the region for that sample is southwest. \n",
    "\n",
    "The benefit of using one-hot encoding is that by not placing a numerical value on the categories, we do not create a relationship among them where there may not exist one. For example, giving a higher value to southwest compare to northeast in region attribute could cause the machine learning algorithm to pick an inexisting relationship among attributes. One-hot encoding alleviates this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657c2ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "cat_attrs = ['sex', 'region', 'smoker']\n",
    "\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(insurance[cat_attrs])\n",
    "ohe_train = pd.DataFrame(ohe.transform(strat_train_set[cat_attrs]).toarray())\n",
    "ohe_test = pd.DataFrame(ohe.transform(strat_test_set[cat_attrs]).toarray())\n",
    "\n",
    "# Drop categorical data\n",
    "strat_train_set.drop(cat_attrs, axis=1, inplace=True)\n",
    "strat_test_set.drop(cat_attrs, axis=1, inplace=True)\n",
    "\n",
    "# Replace with one-hot encoded data\n",
    "strat_train_set = strat_train_set.join(ohe_train)\n",
    "strat_test_set = strat_test_set.join(ohe_test)\n",
    "\n",
    "# Kepp column names as string\n",
    "strat_train_set.columns = strat_train_set.columns.astype(str)\n",
    "strat_test_set.columns = strat_test_set.columns.astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5885b168",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401c8776",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_test_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aeb6f0c",
   "metadata": {},
   "source": [
    "## Feature Scalling\n",
    "\n",
    "Sometimes, data comes in varying degrees of scales. For example, our dataset attribute `bmi.year` is widely distributed. This is evident when we look at the `describe()` function of the dataset and note the difference between max and min statistics. These large numbers can make machine learning models take longer than expected to learn a solution. to make learning easier, it is good practice to \"standarize\" or \"noramlize\" our data. There are two main ways by which this can be achieved:\n",
    "\n",
    "- min-max scaling:\n",
    "  - We use the difference between the minimum and maximum values in the dataset to keep data between 0 and 1.\n",
    "- standarization:\n",
    "  - We use the mean to \"de-mean\" the data. Then, we divide the data by the standard deviation to scale values to unit variances.\n",
    "\n",
    "Note that the main difference is that min-max gives values between 0 and 1 and standarization does not.\n",
    "\n",
    "There is no particular rule to when to use each type of scaling. It is a good idea to try both and compare how much each improves data prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3773622",
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0ab13d",
   "metadata": {},
   "source": [
    "As a side note, it can be also a good idea to scale the charges attribute. This is common practice in machine learning, but it requires reversing this scaling to obtain the true estimate. Because we attempt to keep this workshop as simple as possible we will avoid this step for now. Further, this step is usually taken when the value is trully large such as in the quatrillions and above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e317d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "\n",
    "to_scale = ['bmi.year']\n",
    "# We use two scalers to isolate both datasets\n",
    "ss_train = StandardScaler()\n",
    "ss_test = StandardScaler()\n",
    "# mm_train = MinMaxScaler()\n",
    "# mm_test = MinMaxScaler()\n",
    "\n",
    "strat_train_set[to_scale] = ss_train.fit_transform(strat_train_set[to_scale])\n",
    "strat_test_set[to_scale] = ss_test.fit_transform(strat_test_set[to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbff5d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_set.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9ea13f",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "\n",
    "There is a plethora of different machine learning models. Depending on the application, some models may be better than others. In this case, we are dealing with a classification problem. Because of this, some recomended models to try are:\n",
    "\n",
    "- Ordinary Least Squares\n",
    "- Ridge Regression\n",
    "- Lasso\n",
    "- Elastic Net\n",
    "- Stochastic Gradient Descent\n",
    "- Multi-Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914b5f01",
   "metadata": {},
   "source": [
    "For training, we remove the labels from the training data. Leaving them in the dataset will be reminiscent to giving test answers to a class. It is common practice to use an X variable for the de-labeled data and y for the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d708265",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "# Remove labels.\n",
    "X = strat_train_set.drop(['charges'], axis=1)\n",
    "# Put labels in different variable\n",
    "y = strat_train_set['charges']\n",
    "\n",
    "# Here it is where the magic happend\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3948e63",
   "metadata": {},
   "source": [
    "In order for us to distinguish among models, it is a good idea to pick an accuracy estimator. There are many accuracy estimators that are used in different circumstances. Some of the most used are root mean squared error (RMSE) and mean absolute error (MAE). We highly recomend you read about other accuracy estimators for these estimators have special applications for different goals in data science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d550a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "train_pred = model.predict(X)\n",
    "\n",
    "test_X = strat_test_set.drop(['charges'], axis=1)\n",
    "test_pred = model.predict(test_X)\n",
    "test_y = strat_test_set['charges']\n",
    "\n",
    "train_rmse = np.sqrt(mean_squared_error(y, train_pred))\n",
    "test_rmse = np.sqrt(mean_squared_error(test_y, test_pred))\n",
    "\n",
    "train_mae = mean_absolute_error(y, train_pred)\n",
    "test_mae = mean_absolute_error(test_y, test_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1ffadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training Score: {train_rmse} | Testing Score: {test_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237f35a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training Score: {train_mae} | Testing Score: {test_mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37e2ade",
   "metadata": {},
   "source": [
    "As an interesting observation, testing a linear regressor produces a score that is worse for training dataset than testing dataset. This is because the the model may not be powerful enough for learning the relationships. Testing with a RandomForestRegressor produces a much better score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec57060b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_pred[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba01e8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_y[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b37c73",
   "metadata": {},
   "source": [
    "# Model Fine Tuning\n",
    "\n",
    "As it can be appreciated, the scores obtained above are not phenomenal. The model definetely learns something, but the score reglects that when the model is put to the test, it still struggles. There can be many reasons for this, but one of the main reasons is that the model has not been fine tuned. Machine learning models come with pre-set attributes that may or may not be the best for a particular dataset. Because of this, it is a good idea to test different parameters. Often, testing new parameters will help the model perform better. Check out scikit-learn's documentation to find out about what parameters you can test to try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4b7858",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Random Forest Regressor's\n",
    "param_grid = [\n",
    "    {\n",
    "        'n_estimators': [50, 75, 100, 125, 150],\n",
    "        'criterion': ['squared_error', 'absolute_error', 'poisson'],\n",
    "    }\n",
    "]\n",
    "model = RandomForestRegressor()\n",
    "grid_search = GridSearchCV(model, param_grid, cv=10, scoring='neg_mean_absolute_error', return_train_score=True, n_jobs=7)\n",
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ede57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "train_pred = best_model.predict(X)\n",
    "\n",
    "test_X = strat_test_set.drop(['charges'], axis=1)\n",
    "test_pred = best_model.predict(test_X)\n",
    "test_y = strat_test_set['charges']\n",
    "\n",
    "train_rmse = np.sqrt(mean_squared_error(y, train_pred))\n",
    "test_rmse = np.sqrt(mean_squared_error(test_y, test_pred))\n",
    "\n",
    "train_mae = mean_absolute_error(y, train_pred)\n",
    "test_mae = mean_absolute_error(test_y, test_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbe8cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training Score: {train_rmse} | Testing Score: {test_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363c4569",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training Score: {train_mae} | Testing Score: {test_mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2988384f",
   "metadata": {},
   "source": [
    "Although slight, some improvement was made. Further fine tunning could make the score better."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
